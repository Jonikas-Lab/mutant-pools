#!/usr/bin/env python2.7
""" Take a deepseq alignment file; group the reads into insertional mutants.
Output a line-per-mutant file containing position info, gene annotation data (optional), total/perfect read count, number of distinct sequences, and some of the sequences/counts (optional), and a summary of read/mutant counts etc. 
Also output a line-per-gene file containing gene ID/name/position/annotation and the number and read-counts of mutants that were inserted into that gene (optional, NOT IMPLEMENTED YET).
Output files are in simple tab-separated plaintext format, with all header/summary lines starting with #.

Grouping reads into mutants is currently done by alignment position (other options such as sequence clustering or grouping 1bp-adjacent positions together may be implemented later). 

The input file should be a SAM-format deepseq alignment file created by bowtie, novoalign, or other deepseq aligner programs (tested mainly on bowtie), with optionally a metadata file created by my deepseq_alignment_wrapper.py or deepseq_preprocessing_wrapper.py scripts.
The program assumes the SAM file contains only unique matches (i.e. each read was reported as aligning to at most one genomic location).
It also only deals with single-end alignments at the moment.

 -- Weronika Patena, Jonikas Lab, Carnegie Institution, 2011

USAGE: mutant_count_alignments.py [options] outfile """

# basic library
import sys, os, time
import unittest
import pickle
# other packages
import HTSeq
# my modules
from general_utilities import write_header_data
from testing_utilities import run_functional_tests
import mutant_IB_analysis

######################################################### Main function code ####################################################

def define_option_parser():
    """ Populates and returns an optparse option parser object, with __doc__ as the usage string."""
    from optparse import OptionParser
    parser = OptionParser(__doc__)

    ### Input files and basic descriptions
    # MAYBE-TODO make it possible to put multiple files for all these?
    parser.add_option('-c', '--casette_side_reads', default=None, metavar='FILE', 
                      help="File containing cassette-side reads (from RISCC or ChlaMmeSeq protocol or such; "
                          +"orientation defined with -d, cassette end defined with -e). Required")
    parser.add_option('-b', '--internal_barcodes', default=None, metavar='FILE', 
                      help="File containing clustered internal barcode reads (from RISCC protocol or such), "
                          +"giving the IB centroid seq and a list of read IDs in that cluster (generated by ____) "
                          +"(read IDs should be the same as matching cassette-side reads). Required.")
    # TODO finish the program that GENERATES that file!  Could use plaintext or python pickle files or something...
    parser.add_option('-g', '--genome_side_reads', default=None, metavar='FILE', 
                      help="File containing genome-side reads (from RISCC protocol or such; in orientation toward the cassette). "
                          +"Should have same read IDs as matching cassette-side reads, and be from the same side. Optional.")
    # MAYBE-TODO make the IB file optional and allow the cluster file to be based on cassette-side seqs? Is that a good idea?
    # MAYBE-TODO make the IB+cluster files optional, and use the old clustering-by-alignment method in that case?
    parser.add_option('-e', '--read_cassette_end', choices=mutant_IB_analysis.SEQ_ENDS, default='5prime', 
                      metavar='|'.join(mutant_IB_analysis.SEQ_ENDS), 
                      help="Which end of the cassette are the sequenced reads from? (default %default).")
    parser.add_option('-d','--relative_read_direction', choices=mutant_IB_analysis.RELATIVE_READ_DIRECTIONS, default='outward',
                      metavar='|'.join(mutant_IB_analysis.RELATIVE_READ_DIRECTIONS), 
                      help="Are the cassette-side reads oriented inward or outward to the cassette? (default %default).")

    ### Functionality options
    # gene-finding and gene-annotation options 
    parser.add_option('-A', '--gene_annotation_folder', default='~/experiments/reference_data/chlamy_annotation', metavar='FOLDER', 
                      help="Folder containing gene position and annotation files (files should be from Phytozome: "
                          +"gff file with gene positions, *_annotation_info.txt, maybe *_defline.txt etc) (default %default)")
    # TODO change default to be based on an environmental variable!
    parser.add_option('-G', '--genome_version', type='int', default=5, metavar='G', 
                      help="Which genome version the input files were aligned against - picks the matching gene position "
                          +"and annotation/etc files from the -A folder (4 for v4.* genome, 5 for v5.*, etc) (default %default)")
    # TODO pick the correct gene/annotation files out of the folder; make sure it's consistent with the alignment genome!
    parser.add_option('--detailed_gene_features', action="store_true", default=True,
                      help="Find out what part of the gene (UTR,intron,exon) a mutant hit, based on the -g file "
                          +"(default %default). May take a lot of memory - increase --N_detail_run_groups to fix that.")
    parser.add_option('--no_detailed_gene_features', action="store_false", dest='detailed_gene_features',
                      help="Turns --detailed_gene_features off.")
    parser.add_option('--N_detail_run_groups', type="int", default=5, metavar='N', 
                      help="How many passes to split reading the detailed_gene_features into (default %default) "
                          +"- may take a lot of memory (and CPU) if read in a single pass; too many passes waste CPU.")
    # MAYBE-TODO add a "flank" option (with variable size), to catch mutants that are in the flanks of genes? Do we care?
    # MAYBE-TODO add "distance from gene start" and "distance from gene end" fields.

    # how to treat cassette-aligned sequences and other non-nuclear ones
    parser.add_option('-i', '--ignore_cassette', action='store_true', default=False,
                      help="Ignore reads aligning to cassette (just print total count in the header as removed) "
                          +"(default %default)")
    parser.add_option('-I', '--separate_cassette', action='store_true', default=False,
                      help="Like -c, but also add a *_cassette.txt file with ONLY reads aligning to cassette "
                          +"(and print total non-cassette count in the header of that file as removed) (default %default)")

    # adjacent flanking seq counting/merging
    parser.add_option('-D', '--adjacent_max_distance', type='int', default=1, metavar='N',
                      help="Count/merge adjacent mutants only if they're at most N bases distant; (default %default)")

    # extremely minor functionality options, do we even care??  TODO do we ever see undefined alignment regions?
    parser.add_option('--treat_unknown_as_match', action="store_true", default=False, 
                      help="When counting perfect reads, treat undefined alignment regions as matches (default %default)")
    parser.add_option('--dont_treat_unknown_as_match', action="store_false", dest='treat_unknown_as_match',
                      help="Turn -u off.")

    ### output format options
    parser.add_option('-o', '--sort_data_key', choices=['position','read_count','none'], default='position', 
                      metavar='position|read_count|none', help="Sort the output data: by alignment position, read count, "
                         +"or don't sort at all (default %default) - sorting may be slow for large datasets!")

    parser.add_option('-V', '--verbosity_level', action="store_true", default=1, 
                      help="How much information to print to STDOUT: 0 - nothing, 1 - summary only, "
                          +"2 - summary and progress reports. (Default %default).")
    parser.add_option('-q', '--quiet', action="store_const", const=0, dest='verbosity_level', help="Equivalent to -V 0.")
    parser.add_option('-v', '--verbose', action="store_const", const=2, dest='verbosity_level', help="Equivalent to -V 2.")

    ### test options
    parser.add_option('-t','--test_functionality', action='store_true', default=False, 
                      help="Run the built-in unit test suite (ignores all other options/arguments; default %default).")
    parser.add_option('-T','--test_run', action='store_true', default=False, 
                      help="Run on a test input file, check output against reference files. "
                          + "Ignores all other options/arguments. (default %default).")

    return parser

# TODO merge this with a similar code bit in mutant_join_datasets.py to minimize code duplication
def save_dataset_files(dataset, outfile, verbosity_level=0, if_pickle=True, count_cassette=True, count_other=True, 
                       sort_data_by='position', options="N/A"):
    """ Print summary and data to output file; optionally print summary to stdout; optionally pickle dataset to picklefile. 
    
    The options argument is only used to be printed in the header to make it clear how the file was generated - 
     it should be the applicable optparse options object if there is one, or a text message otherwise.
    """
    # print summary info to stdout if desired
    if verbosity_level>1: print "\nDATA SUMMARY:"
    if verbosity_level>0: dataset.print_summary(count_cassette=count_cassette, count_other=count_other)
    # print full data to outfile
    if verbosity_level>1: print "printing output - time %s."%time.ctime()
    with open(outfile,'w') as OUTFILE:
        write_header_data(OUTFILE,options)
        OUTFILE.write("### SUMMARY:\n")
        dataset.print_summary(OUTFILE, line_prefix="#  ", header_prefix="## ", 
                              count_cassette = count_cassette, count_other=count_other)
        OUTFILE.write("### HEADER AND DATA:\n")
        dataset.print_data(OUTPUT=OUTFILE, sort_data_by=sort_data_by, header_line=True, header_prefix='# ')
    # print pickled dataset to picklefile, if desired
    if if_pickle:
        outfile_basename = os.path.splitext(outfile)[0]
        pickled_outfile = outfile_basename + '.pickle'
        with open(pickled_outfile,'w') as PICKLEFILE:
            pickle.dump(dataset, PICKLEFILE, 0)


def main(outfile, options):
    """ Run the main functionality of the module (see module docstring for more information), excluding testing.
    The options argument should be generated by an optparse parser.
    """
    ### parse/process/reformat some options
    options.ignore_cassette |= options.separate_cassette
    # MAYBE-TODO change outfile to a folder?  Since it'll have three things in it now...
    outfile_basename = os.path.splitext(outfile)[0]
    # MAYBE-TODO let -C take an optional argument to put the cassette files elsewhere?
    cassette_outfile = outfile_basename + '_cassette.txt'

    ### generate empty alignment set object with basic read position/orientation properties defined by options
    all_alignment_data = mutant_IB_analysis.Insertional_mutant_pool_dataset(options.read_cassette_end, 
                                                                            options.relative_read_direction)
    if options.separate_cassette:
        cassette_alignment_data = mutant_IB_analysis.Insertional_mutant_pool_dataset(options.read_cassette_end, 
                                                                                     options.relative_read_direction)

    ### MAYBE-TODO some kind of metadata parsing?  If so, copy relevant options and code from mutant_count_alignments.py.
    # TODO do we want to deal with metadata in the new IB+Carette pipeline? How?
    # This is mostly relevant to the cassette-side file, since that one had some reads removed due to not matching the expected 
    #  structure, etc.  But there can also be metadata for the IB clustering, and for genome-side alignment... 
    #  MAYBE-TODO include that in the same file or a separate one? Do we even care?

    # Assuming input isn't collapsed to unique - it makes no sense with RISCC or IB data, since read IDs are important! 
    # MAYBE-TODO unless I write something where we can do the alignments on collapsed-to-unique seqs but the look up the read IDs
    #  by sequence?  Probably not very useful, since the genome-side seqs will mostly all be unique anyway, 
    #  and doing this only to the cassette-side reads would save less than half of the alignment work.

    ### parse input file and store data - the add_alignment_reader_to_data function here does pretty much all the work!
    # TODO TODO TODO rewrite this bit for new IB+Carette pipeline!  Single cassette-side infile (may be in parts), single genome-side infile (may be in parts), need to use the IB cluster stuff...
    for infile in infiles:
        # if this is a new-style *_genomic-unique.sam file and has a matching *_cassette.sam file, parse that file too
        part_infiles = [infile]
        if infile.endswith('_genomic-unique.sam'):
            cassette_file = infile[:-len('_genomic-unique.sam')] + '_cassette.sam'
            if os.path.exists(cassette_file):
                part_infiles.append(cassette_file)
        for part_infile in part_infiles:
            # initialize a parser for the SAM infile
            if options.verbosity_level>1: 
                print "parsing input file %s - time %s."%(part_infile, time.ctime())
            infile_reader = HTSeq.SAM_Reader(part_infile)
            # fill the new alignment set object with data from the infile parser
            all_alignment_data.add_alignment_reader_to_data(infile_reader, 
                                        uncollapse_read_counts = options.input_collapsed_to_unique, 
                                        ignore_cassette = options.ignore_cassette, cassette_only = False, 
                                        treat_unknown_as_match = options.treat_unknown_as_match)
            if options.separate_cassette:
                cassette_alignment_data.add_alignment_reader_to_data(infile_reader, 
                                        uncollapse_read_counts = options.input_collapsed_to_unique, 
                                        ignore_cassette = False, cassette_only = True, 
                                        treat_unknown_as_match = options.treat_unknown_as_match)

    ### optionally merge some mutant categories?
    # It makes no sense to merge adjacent mutants when the mutants are based on IB clustering rather than position.
    # MAYBE-TODO implement merging opposite-tandem mutants (two sides of same two-cassette insertion) based on position?  
    #  That means merging two different IBs... This should be done for same-side cases and ALSO for 3'+5' cases, 
    #  which we don't have any of yet, so can probably skip it for now...
    # If we do merging, change the counting below to print the data to MERGEFILE/CASSETTE_MERGEFILE rather than sys.stdout!

    ### count adjacent mutants, even if not doing any merging - just print to STDOUT
    all_alignment_data.count_adjacent_mutants(max_distance_to_print = options.adjacent_max_distance, 
                              max_distance_to_count = 10000, count_cassette_chromosomes = False,
                              count_other_chromosomes = True, OUTPUT = sys.stdout)
    if options.separate_cassette:
        cassette_alignment_data.count_adjacent_mutants(max_distance_to_print = options.adjacent_max_distance, 
                              max_distance_to_count = 10, count_cassette_chromosomes = True, 
                              count_other_chromosomes = False, OUTPUT = sys.stdout)
    # MAYBE-TODO make an option for max_distance_to_count?  I'm using a much lower one for cassette because it's so dense.

    ### optionally parse gene position/info files and look up the genes for each mutant in the data
    # TODO TODO TODO rewrite this bit for new IB+Carette pipeline!  Use gene file and any annotation files from folder. 
    #   (annotation files are a second priority)
    if options.gene_position_reference_file is not None:
        genefile = options.gene_position_reference_file
        if options.verbosity_level>1: print "adding genes from file %s to mutant data - time %s."%(genefile, time.ctime())
        all_alignment_data.find_genes_for_mutants(genefile, detailed_features=options.detailed_gene_features, 
                                                  N_run_groups=options.N_detail_run_groups, 
                                                  verbosity_level=options.verbosity_level)

        # if we have gene info, optionally also add annotation
        if options.gene_annotation_file:
            if options.verbosity_level>1: 
                print "adding gene annotation from file %s - time %s."%(options.gene_annotation_file, time.ctime())
            all_alignment_data.add_gene_annotation(options.gene_annotation_file, 
                       if_standard_Phytozome_file=options.annotation_file_standard_type, print_info=(options.verbosity_level >= 2))

    ### output data to files
    save_dataset_files(all_alignment_data, outfile, options.verbosity_level, True, True, True, 
                         True, options.sort_data_key, options)
    # TODO write some info about all the other files that go with this one (pickle, merging-info, *cassette*)

    if options.separate_cassette:
        save_dataset_files(cassette_alignment_data, cassette_outfile, 0, True, False, False, 
                             True,  options.sort_data_key, options)
        # TODO probably write some extra bit of info about this being the cassette-file to MAINFILENAME


# TODO need between-mutant sanity checks!  Like cases with the same cassette-side seq in different mutants (when it's genome-aligned), and cases with very close positions, and such.

# TODO write separate program for removing some mutants based on other file


######################################################### Testing and main ####################################################

# TODO make new tests for new IB+Carette pipeline!
def do_test_run():
    """ Test run: run script on test infile, compare output to reference file."""
    test_folder = "test_data"
    aln_infile0 = "test_data/INPUT_alignment0_old-format.sam"
    aln_infile1 = "test_data/INPUT_alignment1_genomic-unique.sam"
    aln_infile2 = "test_data/INPUT_alignment2_for-genes.sam"
    aln_infile3 = "test_data/INPUT_alignment3_for-merging.sam"
    gff_genefile = "test_data/INPUT_gene-data-1_all-cases.gff3"
    dataset_to_remove = "test_data/INPUT_mutants_to_remove.txt"

    test_runs = [
                 ('cassette-end-5prime', "-e 5prime -r forward -n3 -L", [aln_infile1]),
                 ('cassette-end-3prime', "-e 3prime -r forward -n3 -L", [aln_infile1]),
                 ('read-direction-reverse', "-r reverse -e 5prime -n3 -L", [aln_infile1]),
                 ('unknown-as-match', "--treat_unknown_as_match -e 5prime -r forward -n3 -L", [aln_infile1]),
                 ('dont-count-cassette', "-l -e 5prime -r forward -n3 -L", [aln_infile1]),
                 ('ignore-cassette', "-c -e 5prime -r forward -n3 -L", [aln_infile1]),
                 ('separate-cassette', "-C -e 5prime -r forward -n3 -L", [aln_infile1]),
                 ('sorted-by-count', "-o read_count -e 5prime -r forward -n3 -L", [aln_infile1]),
                 ('with-gene-info_merged', "-e 5prime -r forward -g %s -n0"%gff_genefile, [aln_infile2]),
                 ('with-gene-info_unmerged', "-B -e 5prime -r forward -g %s -n0"%gff_genefile, [aln_infile2]),
                 ('multiple-infiles', "-e 5prime -r forward -n0 -L", [aln_infile1,aln_infile2]),
                 ('dont-merge-tandems', "-n0", [aln_infile3]),
                 ('merge-adjacent-none', "-n0 -Q -Y0", [aln_infile3]),
                 ('merge-adjacent1-r3', "-MQ -D1 -w3 -Y0 -n0", [aln_infile3]),
                 ('merge-adjacent1-r1', "-MQ -D1 -w1 -Y0 -n0", [aln_infile3]),
                 ('merge-adjacent2-r3', "-MQ -D2 -w3 -Y0 -n0", [aln_infile3]), 
                 ('remove-from-other-all', "-x %s -n0"%dataset_to_remove, [aln_infile2]), 
                 ('remove-from-other-min4', "-x %s -z4 -n0"%dataset_to_remove, [aln_infile2]), 
                 ('remove-from-other-perfect', "-x %s -p -z4 -n0"%dataset_to_remove, [aln_infile2]),
                 ('remove-not-other-all', "-X %s -n0"%dataset_to_remove, [aln_infile2]), 
                 ('remove-not-other-min4', "-X %s -Z4 -n0"%dataset_to_remove, [aln_infile2]), 
                 ('remove-not-other-perfect', "-X %s -P -Z4 -n0"%dataset_to_remove, [aln_infile2]),
                 ('old-infile-format', "-e 5prime -r forward -n3 -L", [aln_infile0]),
                ]
    # TODO add run-test for removing data from multiple files?
    # MAYBE-TODO add run-test for a metadata file with 5' and 3' read counts?
    # MAYBE-TODO add run-tests for other mutant-merging options?  But they all have pretty good unit-tests.
    # MAYBE-TODO add run-test for --gene_annotation_file?
    # MAYBE-TODO add run-test for --input_collapsed_to_unique?  Or is that unit-tested already?

    # convert tests into (testname, arg_and_infile_string) format, adding the options that are always used
    test_names_and_args = [('count-aln__'+testname, test_args+' -q '+' '.join(infiles)) 
                           for testname,test_args,infiles in test_runs]

    parser = define_option_parser()
    argument_converter = lambda parser,options,args: (args[:-1], args[-1], options)
    return run_functional_tests(test_names_and_args, parser, main, test_folder, 
                                argument_converter=argument_converter, append_to_outfilenames='.txt') 


class Testing(unittest.TestCase):
    """ Unit-tests this module. """

    def test__(self):
        print "NO UNIT-TESTS FOR THIS MODULE"


if __name__ == "__main__":
    """ Allows both running and importing of this file. """

    parser = define_option_parser()
    (options, args) = parser.parse_args()

    # if run with -t or -T option, do the relevant tests and quit
    if options.test_functionality:
        print("*** You used the -t option - ignoring all other options/arguments, running the built-in test suite. ***")
        print("\n * unit-tests for the mutant_IB_analysis.py module")
        # to run tests for another file, have to use TextTestRunner, not unittest.main -  make a test suite with 
        #   autodetection of all tests (see http://docs.python.org/library/unittest.html#unittest.TestLoader)
        test_suite_1 = unittest.defaultTestLoader.loadTestsFromModule(mutant_IB_analysis)
        unittest.TextTestRunner(verbosity=1).run(test_suite_1)
        # to run tests for current module, just run unittest.main, passing it only the filename 
        #   (by default it takes all of sys.argv and complains about options/arguments it can't recognize)
        print("\n * unit-tests for this module (%s)"%sys.argv[0])
        unittest.main(argv=[sys.argv[0]])   # unittest.main automatically runs sys.exit()
    if options.test_run:
        print("*** You used the -T option - ignoring all other options and running the built-in example test runs. ***")
        test_result = do_test_run()
        sys.exit(test_result)

    # otherwise parse the arguments and run main function
    try:
        [outfile] = [args]
    except ValueError:
        parser.print_help()
        sys.exit("\nError: exactly one outfile is required! Infiles should be given as options.")
    main(outfile, options)
