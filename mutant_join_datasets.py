#!/usr/bin/env python
""" Join the by-mutant counts from multiple files generated by mutant_count_alignments.py into a single tab-separated file, along with position and gene information for each mutant.

 -- Weronika Patena, Jonikas Lab, Carnegie Institution, 2011

USAGE: mutant_join_datasets.py [options] infile1 [infile2 infile3 ...] outfile """

# basic libraries
import sys, os, time
# other libraries
from collections import defaultdict
import unittest
# my modules
from general_utilities import write_header_data
import mutant_analysis_classes


def do_test_run():
    """ Test run: run script on test infile, compare output to reference file."""
    print "RUN-TESTS NOT IMPLEMENTED"
    # TODO implement


class Testing(unittest.TestCase):
    """ Unit-tests this module. """

    def test__(self):
        print "NO UNIT-TESTS FOR THIS MODULE"


######### Main function code #########

def define_option_parser():
    """ Populates and returns an optparse option parser object, with __doc__ as the usage string."""
    from optparse import OptionParser
    parser = OptionParser(__doc__)

    ### functionality options
    parser.add_option('-G', '--gene_annotation_file', metavar='FILE',
                      help="Tab-separated gene annotated file (must have Cre gene IDs in first column) (default %default)")
    parser.add_option('-p', '--perfect_reads_only', action="store_true", default=False,
                      help="Take perfect read counts (default %default)")
    parser.add_option('-a', '--all_reads', action="store_false", dest='perfect_reads_only',
                      help="Take total read counts (turns -p off).")
    parser.add_option('-m', '--output_only_shared_mutants', action="store_true", default=False,
                      help="Only output the mutants that have non-zero counts in ALL input files (default %default)")
    parser.add_option('-M', '--output_all_mutants', action="store_false", dest='output_only_shared_mutants',
                      help="Output all mutants, including ones that only appear in one input file (turns -o off).")

    ### output format options
    parser.add_option('-H', '--header_level', choices=['0','1','2'], default='2', metavar='0|1|2', 
                      help="Outfile header type:  0 - no header at all, 1 - a single line giving column headers, "
                          + "2 - full header with command, options, date, user etc (default %default) (also see -s)")
    parser.add_option('-s', '--add_summary_to_file', action="store_true", default=True, 
                      help="Print summary at the end of the file (default %default) (also see -H)")
    parser.add_option('-S', '--dont_add_summary_to_file', action="store_false", dest='add_summary_to_file', 
                      help="Turn -s off.")

    ### command-line verbosity options
    parser.add_option('-V', '--verbosity_level', action="store_true", default=1, 
                      help="How much information to print to STDOUT: 0 - nothing, 1 - summary only, "
                          +"2 - summary and progress reports. (Default %default).")
    parser.add_option('-q', '--quiet', action="store_const", const=0, dest='verbosity_level', help="Equivalent to -V 0.")
    parser.add_option('-v', '--verbose', action="store_const", const=2, dest='verbosity_level', help="Equivalent to -V 2.")

    ### test options
    parser.add_option('-t','--test_functionality', action='store_true', default=False, 
                      help="Run the built-in unit test suite (ignores all other options/arguments; default %default).")
    parser.add_option('-T','--test_run', action='store_true', default=False, 
                      help="Run on a test input file, check output against reference files. "
                          + "Ignores all other options/arguments. (default %default).")

    return parser


def parse_gene_annotation_file(gene_annotation_filename, header_list=None, add_empty_fields_to_length=False, 
                               strip_last_fields=0, field_delimiter='.', ignore_comments=False, verbosity_level=1):
    """ Parse tab-separated gene annotation file; return a geneID:data_list dict, and a column header list (if present).
    Try to automatically detect if the file has a header; optionally use header provided; 
     return None for header if none was provided or detected. 
    Remove columns with no contents.
    """
    if verbosity_level>0:
        print " *** Parsing file %s for gene annotation info..."%gene_annotation_filename

    # parse the lines into lists of tab-separated fields
    data_by_row = []
    for line in open(gene_annotation_filename):
        if ignore_comments and line[0]=='#':    continue
        fields = line.strip().split('\t')
        data_by_row.append(fields)
        
    # if the first line doesn't start with a Cre* gene ID, assume it's a header
    if not data_by_row[0][0].startswith("Cre"):
        header = data_by_row[0]
        del data_by_row[0]
        if verbosity_level>0:
            print "Assuming the first line is a header: %s"%'\t'.join(header)
    else: 
        header = None
    # if any of the other lines doesn't start with a Cre* gene ID, fail!
    for row in data_by_row:
        if not row[0].startswith("Cre"):
            sys.exit("Can't parse file %s - found line that doesn't start with a Cre gene ID!"%(gene_annotation_filename, 
                                                                                                '\t'.join(row)))
    # use the header from arguments if provided
    if header_list is not None:
        header = header_list
        if verbosity_level>1: print "Using header provided: %s"%'\t'.join(header)

    # check that all the data lengths line up (if they don't, don't throw an error
    mismatched_lengths = False
    data_lengths = set([len(row) for row in data_by_row])
    if not len(data_lengths)==1:
        if verbosity_level>1 or (not add_empty_fields_to_length and verbosity_level>0):
            print "Warning: not all data rows have the same length! Lengths found: %s"%list(data_lengths)
        mismatched_lengths = True
    if header is not None and len(header) not in data_lengths:
        if verbosity_level>1 or (not add_empty_fields_to_length and verbosity_level>0):
            print("Warning: header has a different number of fields than the data! "
                  +"Header length: %s. Data lengths: %s"%(len(header),list(data_lengths)))
        mismatched_lengths = True
    
    if len(data_lengths)>1 and add_empty_fields_to_length:
        max_length = max(max(data_lengths), len(header))
        if verbosity_level>0:
            print "Data field numbers vary between rows - padding all lower-length data rows to length %s"%max_length
        for row in data_by_row:
            if len(row)<max_length:
                row += ['' for x in range(max_length-len(row))]
        if len(header)<max_length:
            header += ['?' for x in range(max_length-len(header))]
        mismatched_lengths = False

    # remove empty columns (only if all the data lengths match!)
    if not mismatched_lengths:
        data_length = len(header)
        columns_to_remove = []
        for pos in range(data_length):
            values = set([row[pos] for row in data_by_row])
            if len(values)==1:
                value = values.pop()
                if value.strip()=='':
                    if verbosity_level>0:
                        if header:  print "Column %s (%s) is always empty - removing it."%(pos+1, header[pos])
                        else:       print "Column %s is always empty - removing it."%(pos+1)
                    columns_to_remove.append(pos)
                else:
                    if verbosity_level>0:
                        print "Note: all the values in column %s are the same! (%s)"%(pos+1, value)
        for pos in sorted(columns_to_remove, reverse=True):
            if header:  del header[pos]
            for row in data_by_row: 
                del row[pos]

    # convert the list-format data into a by-gene dictionary
    data_by_gene = {}
    for row in data_by_row:
        gene = row[0]
        if strip_last_fields:
            gene = field_delimiter.join(gene.split(field_delimiter)[:-strip_last_fields])
        data = row[1:]
        if gene in data_by_gene:
            if verbosity_level>0:
                print "Warning: gene %s appears twice in the data! Using last appearance."%gene
        data_by_gene[gene] = data
    # remove the first word from the header, since it should be "gene ID" or such
    if header:  del header[0]

    if verbosity_level>0:
        print " *** DONE Parsing gene annotation file"
    return data_by_gene, header


class Mutant_multi_counts():
    """ Simple container class for a mutant with multiple counts from different datasets: 
          contains a position (mutant_analysis_classes.Insertion_position instance), 
          gene data, a main sequence, and a filename:count dictionary (defaultdict with default value 0).
    """
    # TODO I'm not sure if I like this - might want it to be based on the Insertional_mutant_data class in mutant_analysis_classes.py instead of separate like this!  Just use mutant-merging to merge multiple Insertional_mutant_data instances into one, and give the result an extra self.dataset_counts attribute... 

    def __init__(self, position, gene, orientation, gene_feature):
        self.position = position
        self.gene = gene
        self.orientation = orientation
        self.gene_feature = gene_feature
        self.main_sequence = ''
        self.dataset_counts = defaultdict(lambda: 0)


def run_main_function(infiles, outfile, options):
    """ Run the main functionality of the module (see module docstring for more information), excluding testing.
    The options argument should be generated by an optparse parser.
    """

    # TODO this is a ridiculous wall of code, split it into functions!!  Or extract some functionality to Mutant_multi_counts class or something... 

    summary_lines = []
    dataset_combination_info = "every dataset" if options.output_only_shared_mutants else "at least one dataset"

    # parse all infiles, print summaries to stdout if requested
    all_datasets = []
    for infile in infiles:
        if options.verbosity_level>1:   print "parsing input file %s - time %s."%(infile, time.ctime())
        current_dataset = mutant_analysis_classes.Insertional_mutant_library_dataset()
        current_dataset.read_from_file(infile)
        all_datasets.append((infile,current_dataset))
        summary_lines.append("%s mutants in dataset from input file %s"%(len(current_dataset.mutants_by_position), infile))
        if options.verbosity_level>0:   print summary_lines[-1]
        elif options.verbosity_level>1: current_dataset.print_summary()
    
    # get a set of all mutant position we're interested in (either a union or an intersection of those from each infile)
    first_dataset_mutants = all_datasets[0][1].mutants_by_position
    if options.output_only_shared_mutants:  all_mutant_function = set(first_dataset_mutants.keys()).intersection
    else:                                   all_mutant_function = set().union
    all_mutant_positions = all_mutant_function(*[dataset.mutants_by_position.keys() for (infile,dataset) in all_datasets])
    summary_lines.append("total %s mutants present in %s"%(len(all_mutant_positions),dataset_combination_info))
    if options.verbosity_level>0:   print summary_lines[-1]
    
    # for each mutant, merge the position/gene data and the counts per dataset into a single Mutant_multi_counts object
    if options.verbosity_level>1:   print "merging the multi-dataset data for each mutant - time %s."%(time.ctime())
    all_mutants = []
    for mutant_position in all_mutant_positions:
        # TODO most of this mutant-merging could probably just be done using the mutant-merging functionality of the standard mutant class, without writing something completely new for it... This new Mutant_multi_counts class seems like ugly code duplication.
        # make a dictionary of full mutant data per dataset
        current_mutant_data = {}
        for infile,dataset in all_datasets:
            try:                current_mutant_data[infile] = dataset.mutants_by_position[mutant_position]
            except KeyError:    pass
        assert len(current_mutant_data)>0
        # merge the position/gene data from each mutant object into a single Mutant_multi_counts object
        position_set    = set([mutant.position     for mutant in current_mutant_data.values()])
        # MAYBE-TODO I shouldn't be hashing Insertion_position instances, they're mutable! But I'm not changing them here.
        gene_set        = set([mutant.gene         for mutant in current_mutant_data.values()])
        orientation_set = set([mutant.orientation  for mutant in current_mutant_data.values()])
        feature_set     = set([mutant.gene_feature for mutant in current_mutant_data.values()])
        if len(position_set)>1:     raise Exception("Multiple positions found for a mutant in different datasets!")
        if len(gene_set)>1:         raise Exception("Multiple gene locations found for a mutant in different datasets!")
        if len(orientation_set)>1:  raise Exception("Multiple orientations found for a mutant in different datasets!")
        if len(feature_set)>1:      raise Exception("Multiple gene features found for a mutant in different datasets!")
        current_mutant = Mutant_multi_counts(position_set.pop(), gene_set.pop(), orientation_set.pop(), feature_set.pop())
        # add the counts from each dataset to an infile:count dictionary to the Mutant_multi_counts object
        if options.perfect_reads_only:  count_getter_function = lambda mutant: mutant.perfect_read_count
        else:                           count_getter_function = lambda mutant: mutant.total_read_count
        for infile,mutant in current_mutant_data.items():
            current_mutant.dataset_counts[infile] = count_getter_function(mutant)
        # figure out the overall main sequence - if it's always the same, take that, else take the one with most counts
        sequence_set = set([mutant.get_main_sequence() for mutant in current_mutant_data.values()])
        if len(set([seq for seq,count in sequence_set]))==1:      
            current_mutant.main_sequence = sequence_set.pop()[0]
        else:
            if options.verbosity_level>1:
                print("Warning: different main sequences found for a mutant in different datasets! %s  "%sequence_set
                      + "Taking the sequence with the most overall counts.")
            sequence_counts = defaultdict(lambda: 0)
            for mutant in current_mutant_data.values():
                for (seq,count) in mutant.sequences_and_counts.items():
                    sequence_counts[seq] += count
            sequences_by_count = sorted(sequence_counts.iteritems(), key=lambda x: x[1], reverse=True)
            current_mutant.main_sequence = sequences_by_count[0][0]
        # make sure the mutant has a non-zero count in all/any datasets (may not be true if we're taking perfect counts)
        if options.output_only_shared_mutants:
            if all(current_mutant.dataset_counts.values()):     all_mutants.append(current_mutant)
        else:
            if sum(current_mutant.dataset_counts.values())>0:   all_mutants.append(current_mutant)
    if options.perfect_reads_only:  assert len(all_mutants) <= len(all_mutant_positions)
    else:                           assert len(all_mutants) == len(all_mutant_positions)
    summary_lines.append("total %s mutants with a non-zero %s count in %s"%(len(all_mutants), 
                                       ('perfect' if options.perfect_reads_only else 'total'), dataset_combination_info))
    if options.verbosity_level>0:   print summary_lines[-1]

    # if requested, add gene annotation info from separate file
    if not options.gene_annotation_file:
        gene_annotation_dict, gene_annotation_header = None, None
    elif not os.path.lexists(options.gene_annotation_file):
        print "Warning: couldn't find the %s gene annotation file! Going on without it."%options.gene_annotation_file
        gene_annotation_dict, gene_annotation_header = None, None
    else:
        # special case for the Creinhardtii_169_annotation_info.txt file (from README)
        if os.path.basename(options.gene_annotation_file)=='Creinhardtii_169_annotation_info.txt':
            header = ['Phytozome transcript name', 'PFAM', 'Panther', 'KOG', 'KEGG ec', 'KEGG Orthology', 
                      'best arabidopsis TAIR10 hit name', 'best arabidopsis TAIR10 hit symbol', 
                      'best arabidopsis TAIR10 hit defline', 
                      'best rice hit name', 'best rice hit symbol', 'best rice hit defline']
            strip_last_fields = 2
            pad_lines = True
        else:
            header = None
            strip_last_fields = 0
            pad_lines = False
        gene_annotation_dict, gene_annotation_header = parse_gene_annotation_file(options.gene_annotation_file, 
                                          header_list=header, add_empty_fields_to_length=pad_lines, 
                                          strip_last_fields=strip_last_fields, verbosity_level=options.verbosity_level)
        # change spaces to underscores in headers for readability
        if gene_annotation_header:
            gene_annotation_header = [s.replace(' ','_') for s in gene_annotation_header]
        # make a data line for missing data, with the same number of (empty) fields
        missing_gene_annotation_data = ['NO GENE DATA'] + ['' for x in range(len(gene_annotation_dict.values()[0])-1)]

    # print full data to outfile
    if options.verbosity_level>1:   print "printing output to file %s - time %s."%(outfile, time.ctime())
    options.header_level = int(options.header_level)
    with open(outfile,'w') as OUTFILE:
        if options.header_level==2:
            write_header_data(OUTFILE,options)
        if options.add_summary_to_file:
            OUTFILE.write("### SUMMARY:\n")
            for line in summary_lines:
                OUTFILE.write('# %s\n'%line)
        if options.header_level==2:
            OUTFILE.write("### DATA:\n")
        # print header line 
        if options.header_level>0:
            if options.header_level==2:     OUTFILE.write("# ")
            OUTFILE.write("chromosome\tstrand\tmin_position\tfull_position\tgene\torientation\tfeature\tmain_sequence\t")
            OUTFILE.write('\t'.join(['reads_in_'+os.path.splitext(os.path.basename(infile))[0] 
                                     for infile,dataset in all_datasets]))
            if gene_annotation_dict is not None:
                if gene_annotation_header is not None:  OUTFILE.write('\t' + '\t'.join(gene_annotation_header))
                else:                                   OUTFILE.write('\t' + '\tgene_annotation_data')
            OUTFILE.write("\n")
        # print the data for each mutant (sort mutants by position)
        all_mutants.sort(key = lambda m: m.position)
        for mutant in all_mutants:
            # print basic info (chrom, strand, min_pos, full_pos, gene, orientation, feature)
            all_mutant_data = [mutant.position.chromosome, mutant.position.strand, mutant.position.min_position, 
                               mutant.position.full_position, mutant.gene, mutant.orientation, mutant.gene_feature, 
                               mutant.main_sequence]
            # print the read count (total or perfect depending on options) from each dataset
            for infile,dataset in all_datasets:
                all_mutant_data += (mutant.dataset_counts[infile],)
            # print the gene annotation info if present
            if gene_annotation_dict is not None:
                try:                all_mutant_data += gene_annotation_dict[mutant.gene]
                except KeyError:    all_mutant_data += missing_gene_annotation_data
            OUTFILE.write('\t'.join([str(x) for x in all_mutant_data]) + '\n')


if __name__ == "__main__":
    """ Allows both running and importing of this file. """

    parser = define_option_parser()
    (options, args) = parser.parse_args()

    # if ran with -t option, do unit tests and quit
    if options.test_functionality:
        print("*** You used the -t option - ignoring all other options/arguments, running the built-in test suite. ***")
        print("\n * unit-tests for the mutant_analysis_classes.py module")
        # to run tests for another file, have to use TextTestRunner, not unittest.main -  make a test suite with 
        #   autodetection of all tests (see http://docs.python.org/library/unittest.html#unittest.TestLoader)
        test_suite_1 = unittest.defaultTestLoader.loadTestsFromModule(mutant_analysis_classes)
        unittest.TextTestRunner(verbosity=1).run(test_suite_1)
        # to run tests for current module, just run unittest.main, passing it only the filename 
        #   (by default it takes all of sys.argv and complains about options/arguments it can't recognize)
        print("\n * unit-tests for this module (%s)"%sys.argv[0])
        unittest.main(argv=[sys.argv[0]])   # unittest.main automatically runs sys.exit()

    if options.test_run:
        print("*** You used the -T option - ignoring all other options and running the built-in example test runs. ***")
        test_result = do_test_run()
        sys.exit(test_result)

    # otherwise parse the arguments and run main function
    if len(args)<2:
        parser.print_help()
        sys.exit("\nError: at least one infile and exactly one outfile are required!")
    outfile = args[-1]
    infiles = args[:-1]

    run_main_function(infiles, outfile, options)

